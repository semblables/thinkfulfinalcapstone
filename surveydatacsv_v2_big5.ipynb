{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "import io\n",
    "import os\n",
    "import glob\n",
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import statistics as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Loneliness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Sometimes', 'Rarely', 'Often', 'Never'], dtype=object)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/Users/kristiancanler/Documents/Data/dartmouth_dataset/dataset/survey/LonelinessScale.csv'\n",
    "loneliness_data = pd.read_csv(path)\n",
    "\n",
    "# Printing unique values for survey questions\n",
    "pd.unique(loneliness_data.iloc[:, 2:].values.ravel('K'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating copy of dataframe so rerunning this cell doesnt throw errors\n",
    "loneliness = loneliness_data.copy()\n",
    "\n",
    "# Lowering all strings\n",
    "for col in loneliness.iloc[:, 2:]:\n",
    "    loneliness[col] = loneliness[col].str.lower()\n",
    "\n",
    "# Translating string responses to ordinal codes\n",
    "loneliness[loneliness == 'never'] = 0\n",
    "loneliness[loneliness == 'rarely'] = 1\n",
    "loneliness[loneliness == 'sometimes'] = 2\n",
    "loneliness[loneliness == 'often'] = 3\n",
    "\n",
    "# Naming values to be flipped and pairing with reversed questions\n",
    "flip_vars = {'1. I feel in tune with the people around me':\n",
    "                 '1. I do not feel in tune with the people around me',\n",
    "             '4. I do not feel alone':\n",
    "                 '4. I feel alone',\n",
    "             '5. I feel part of a group of friends':\n",
    "                 '5. I do not feel part of a group of friends',\n",
    "             '6. I have a lot in common with the people around me':\n",
    "                 '6. I do not have a lot in common with the people around me',\n",
    "             '9. I am an outgoing person':\n",
    "                 '9. I am not an outgoing person',\n",
    "             '10. There are people I feel close to':\n",
    "                 '10. There are not any people I feel close to',\n",
    "             '15. I can find companionship when I want it':\n",
    "                 '15. I cannot find companionship when I want it',\n",
    "             '16. There are people who really understand me':\n",
    "                 '16. There are not people who really understand me',\n",
    "             '19. There are people I can talk to':\n",
    "                 '19. There are not any people I can talk to',\n",
    "             '20. There are people I can turn to':\n",
    "                 '20. There are not any people I can turn to'}\n",
    "\n",
    "codebook = {\n",
    "    'loneliness': {0: 'never',\n",
    "                   1: 'rarely',\n",
    "                   2: 'sometimes',\n",
    "                   3: 'often',\n",
    "                   4: 'always'}\n",
    "}\n",
    "\n",
    "# Flipping values\n",
    "for var in flip_vars.keys():\n",
    "    # Never to Always\n",
    "    loneliness.loc[loneliness[var]==0, var] = 4\n",
    "    # Rarely to Often\n",
    "    loneliness.loc[loneliness[var]==1, var] = 3\n",
    "    # Sometimes stays Sometimes\n",
    "    # Often to Rarely\n",
    "    loneliness.loc[loneliness[var]==3, var] = 1\n",
    "    \n",
    "# Creating feature which is average or sum of all answers\n",
    "loneliness['loneliness_avg'] = loneliness.iloc[:, 2:].mean(axis=1)\n",
    "loneliness['loneliness_sum'] = loneliness.iloc[:, 2:].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['u00', 'u01', 'u02', 'u03', 'u04', 'u05', 'u07', 'u08', 'u09', 'u10', 'u12', 'u13', 'u14', 'u15', 'u16', 'u17', 'u18', 'u19', 'u20', 'u22', 'u23', 'u24', 'u27', 'u30', 'u31', 'u32', 'u33', 'u34', 'u35', 'u36', 'u39', 'u42', 'u43', 'u44', 'u45', 'u46', 'u47', 'u49', 'u50', 'u51', 'u52', 'u53', 'u56', 'u57', 'u58', 'u59', 'u54']\n"
     ]
    }
   ],
   "source": [
    "all_uid = pd.Series()\n",
    "for df in [loneliness, stress, depression,\n",
    "            flourishing, panas]:\n",
    "    all_uid = all_uid.append(df['uid'])\n",
    "    \n",
    "all_uid = list(all_uid.unique())\n",
    "\n",
    "def diff(df):\n",
    "    return [uid for uid in all_uid if uid not in df.uid.to_list()]\n",
    "\n",
    "missing = {\n",
    "    'loneliness': diff(loneliness),\n",
    "    'stress': diff(stress),\n",
    "    'depression': diff(depression),\n",
    "    'flourishing': diff(flourishing),\n",
    "    'panas' : diff(panas)\n",
    "}\n",
    "missing\n",
    "print(all_uid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Stress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Sometime', 'Fairly often', 'Almost never', 'Very often', 'Never',\n",
       "       nan], dtype=object)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/Users/kristiancanler/Documents/Data/dartmouth_dataset/dataset/survey/PerceivedStressScale.csv'\n",
    "stress_data = pd.read_csv(path)\n",
    "\n",
    "# Printing unique values for survey questions\n",
    "pd.unique(stress_data.iloc[:, 2:].values.ravel('K'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating copy of dataframe so rerunning this cell doesnt throw errors\n",
    "stress = stress_data.copy()\n",
    "\n",
    "# Lowering all strings\n",
    "for col in stress.iloc[:, 2:]:\n",
    "    stress[col] = stress[col].str.lower()\n",
    "\n",
    "# Adding entry to codebook\n",
    "codebook['stress'] = {\n",
    "    0: 'never',\n",
    "    1: 'almost never',\n",
    "    2: 'sometime',\n",
    "    3: 'fairly often',\n",
    "    4: 'very often'\n",
    "}\n",
    "\n",
    "# Translating the answers to ordinal values\n",
    "stress[stress == 'never'] = 0\n",
    "stress[stress == 'almost never'] = 1\n",
    "stress[stress == 'sometime'] = 2\n",
    "stress[stress == 'fairly often'] = 3\n",
    "stress[stress == 'very often'] = 4\n",
    "\n",
    "flip_vars = {'4. In the last month, how often have you felt confident about your ability to handle your personal problems?':\n",
    "                 '4. In the last month, how often have you not felt confident about your ability to handle your personal problems?',\n",
    "             '5. In the last month, how often have you felt that things were going your way?':\n",
    "                 '5. In the last month, how often have you felt that things were not going your way?',\n",
    "             '7. In the last month, how often have you been able to control irritations in your life?':\n",
    "                 '7. In the last month, how often have you not been able to control irritations in your life?',\n",
    "             '8. In the last month, how often have you felt that you were on top of things?':\n",
    "                 '8. In the last month, how often have you felt that you were not on top of things?'\n",
    "            }\n",
    "\n",
    "# Renaming flipped features. This needs to happen before flipping the values\n",
    "stress.rename(flip_vars, axis=1, inplace=True)\n",
    "\n",
    "# Flipping values for flip features\n",
    "for var in list(flip_vars.values()):\n",
    "    stress.loc[stress[var]==0, var] = 4\n",
    "    stress.loc[stress[var]==1, var] = 3\n",
    "    stress.loc[stress[var]==3, var] = 1\n",
    "    stress.loc[stress[var]==4, var] = 0\n",
    "    \n",
    "# Creating feature which is average or sum of all answers\n",
    "stress['stress_avg'] = stress.iloc[:, 2:].mean(axis=1)\n",
    "stress['stress_sum'] = stress.iloc[:, 2:].sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Depression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Not at all', 'Several days', 'More than half the days',\n",
       "       'Nearly every day', 'Not difficult at all', 'Very difficult',\n",
       "       'Somewhat difficult', nan, 'Extremely difficult'], dtype=object)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/Users/kristiancanler/Documents/Data/dartmouth_dataset/dataset/survey/PHQ-9.csv'\n",
    "depression_data = pd.read_csv(path)\n",
    "\n",
    "# Printing unique values for survey questions\n",
    "pd.unique(depression_data.iloc[:, 2:].values.ravel('K'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating copy of dataframe so rerunning this cell doesnt throw errors\n",
    "depression = depression_data.copy()\n",
    "\n",
    "# Lowering all strings\n",
    "for col in depression.iloc[:, 2:]:\n",
    "    depression[col] = depression[col].str.lower()\n",
    "    \n",
    "# Adding entry to codebook\n",
    "codebook['depression'] = {\n",
    "    0: 'not at all / not difficult at all',\n",
    "    1: 'several days / somewhat difficult',\n",
    "    2: 'more than half the days / very difficult',\n",
    "    3: 'nearly every day / extremely difficult'\n",
    "}\n",
    "\n",
    "# Creating numeric equivalents for ordinal variables\n",
    "depression[depression == 'not at all'] = 0\n",
    "depression[depression == 'several days'] = 1\n",
    "depression[depression == 'more than half the days'] = 2\n",
    "depression[depression == 'nearly every day'] = 3\n",
    "depression[depression == 'not difficult at all'] = 0\n",
    "depression[depression == 'somewhat difficult'] = 1\n",
    "depression[depression == 'very difficult'] = 2\n",
    "depression[depression == 'extremely difficult'] = 3\n",
    "\n",
    "# This question is so long it makes the visualization hard to format. I'll just add\n",
    "# a (+) as a reminder the original question is longer\n",
    "depression.rename({'Moving or speaking so slowly that other people could have noticed. Or the opposite being so figety or restless that you have been moving around a lot more than usual':\n",
    "                   'Moving or speaking so slowly that other people could have noticed. (+)'},\n",
    "             axis=1,\n",
    "             inplace=True)\n",
    "\n",
    "# Creating mean and sum features\n",
    "depression['depression_avg'] = depression.iloc[:, 2:].mean(axis=1)\n",
    "depression['depression_sum'] = depression.iloc[:, 2:].sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Flourishing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More info on flourishing scale: https://ggsc.berkeley.edu/images/uploads/The_Flourishing_Scale.pdf\n",
    "\n",
    "path = '/Users/kristiancanler/Documents/data/dartmouth_dataset/dataset/survey/FlourishingScale.csv'\n",
    "flourishing = pd.read_csv(path)\n",
    "\n",
    "# Creating mean and sum features\n",
    "flourishing['flourishing_avg'] = flourishing.iloc[:, 2:].mean(axis=1)\n",
    "flourishing['flourishing_sum'] = flourishing.iloc[:, 2:].sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### PANAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:1418: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n"
     ]
    }
   ],
   "source": [
    "# More info on panas scale: https://ogg.osu.edu/media/documents/MB%20Stream/PANAS.pdf\n",
    "path = '/Users/kristiancanler/Documents/data/dartmouth_dataset/dataset/survey/panas.csv'\n",
    "panas = pd.read_csv(path)\n",
    "\n",
    "# Lowering column names\n",
    "panas.columns = panas.columns.str.lower()\n",
    "\n",
    "# Creating mean and sum features for positive and negative affect\n",
    "pos_affect = ['interested', 'strong', 'enthusiastic', 'proud', 'alert', 'inspired',\n",
    "              'determined', 'attentive', 'active']\n",
    "panas['panas_pos_avg'] = panas.loc[:, pos_affect].mean(axis=1)\n",
    "panas['panas_pos_sum'] = panas.loc[:, pos_affect].sum(axis=1)\n",
    "\n",
    "neg_affect = ['distressed', 'upset', 'guilty', 'scared', 'hostile',\n",
    "              'irritable', 'nervous', 'jittery', 'afraid']\n",
    "panas['panas_neg_avg'] = panas.loc[:, neg_affect].mean(axis=1)\n",
    "panas['panas_neg_sum'] = panas.loc[:, neg_affect].sum(axis=1)\n",
    "\n",
    "panas['panas_net_avg'] = panas.panas_pos_avg - panas.panas_neg_avg\n",
    "panas['panas_net_sum'] = panas.panas_pos_sum - panas.panas_neg_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Single Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Single Student-wise Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot = pd.pivot_table(\n",
    "    panas[['uid', 'type',\n",
    "          'panas_pos_avg', 'panas_pos_sum',\n",
    "          'panas_neg_avg', 'panas_neg_sum',\n",
    "          'panas_net_avg', 'panas_net_sum']],\n",
    "   index='uid',\n",
    "   columns='type'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dfs(type_):\n",
    "\n",
    "        return panas.loc[\n",
    "                panas.type==type_,\n",
    "                ['uid',\n",
    "                 'panas_pos_avg', 'panas_pos_sum',\n",
    "                 'panas_neg_avg', 'panas_neg_sum',\n",
    "                 'panas_net_avg', 'panas_net_sum']\n",
    "        ].merge(\n",
    "            flourishing.loc[\n",
    "                flourishing.type==type_,\n",
    "                ['uid',\n",
    "                 'flourishing_avg', 'flourishing_sum']\n",
    "            ],\n",
    "            on='uid',\n",
    "            how='outer'\n",
    "        ).merge(\n",
    "            depression.loc[\n",
    "                depression.type==type_,\n",
    "                ['uid',\n",
    "                 'depression_avg', 'depression_sum']\n",
    "            ],\n",
    "            on='uid',\n",
    "            how='outer'\n",
    "        ).merge(\n",
    "            stress.loc[\n",
    "                stress.type==type_,\n",
    "                ['uid',\n",
    "                 'stress_avg', 'stress_sum']\n",
    "            ],\n",
    "            on='uid',\n",
    "            how='outer'\n",
    "        ).merge(\n",
    "            loneliness.loc[\n",
    "                loneliness.type==type_,\n",
    "                ['uid',\n",
    "                 'loneliness_avg', 'loneliness_sum']\n",
    "            ],\n",
    "            on='uid',\n",
    "            how='outer'\n",
    "        )\n",
    "\n",
    "pre_survey_uid = merge_dfs('pre')\n",
    "post_survey_uid = merge_dfs('post')\n",
    "for df in [pre_survey_uid, post_survey_uid]:\n",
    "    df.uid = df.uid.str.split('u').str.get(1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding dfs with id indexed out\n",
    "avg_survey = pre.iloc[:, 1:].add(post.iloc[:, 1:], fill_value=0)\n",
    "\n",
    "# Producing average of the dfs by then dividing the df\n",
    "# elementwise with .applymap\n",
    "avg_survey = avg_survey.applymap(lambda x: x / 2)\n",
    "\n",
    "# Adding id back in an returning it to beginning of df\n",
    "avg_survey['uid'] = pre.uid.copy()\n",
    "avg_survey = avg[avg.columns.to_list()[-1:] + avg.columns.to_list()[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/kristiancanler/Documents/Data/dartmouth_dataset/dataset/my_dfs/'\n",
    "\n",
    "dfs = {'pre_survey.csv': pre_survey,\n",
    "       'post_survey.csv': post_survey,\n",
    "       'avg_survey.csv': avg_survey}\n",
    "\n",
    "for key in dfs:\n",
    "    output_file = os.path.join(path, key)\n",
    "    dfs[key].to_csv(output_file, index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
